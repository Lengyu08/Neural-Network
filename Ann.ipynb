{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import struct\n",
    "\n",
    "import numpy as np                  # 矩阵\n",
    "import matplotlib.pyplot as plt     # 绘图\n",
    "\n",
    "from numba import njit              # 加速 cpu\n",
    "from numba import cuda              # 加速 gpu(cuda)\n",
    "from pathlib import Path            # 处理路径\n",
    "\n",
    "from Activation import Activation\n",
    "from ProgressBar import ProgressBar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bypass(x):\n",
    "    return x\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def softmax(x):\n",
    "    exp=np.exp(x - x.max())\n",
    "    return exp / exp.sum()\n",
    "\n",
    "def d_softmax(data):\n",
    "    sm = softmax(data)\n",
    "    return np.diag(sm) - np.outer(sm,sm)\n",
    "\n",
    "def d_tanh(data):\n",
    "    return 1 / ((np.cosh(data)) ** 2)\n",
    "\n",
    "def d_bypass(x):\n",
    "    return 1\n",
    "\n",
    "differential = {softmax:d_softmax, tanh:d_tanh, bypass:d_bypass}\n",
    "d_type = {bypass:'times', softmax:'dot', tanh:'times'} # tanh 和 bypass都进行了优化而 softmax没有优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [28*28, 100, 10]\n",
    "activation = [bypass, tanh, softmax]\n",
    "distribution = [\n",
    "    {}, # leave it empty !\n",
    "    {'b':[0, 0],'w':[-math.sqrt(6 / (dimensions[0] + dimensions[1])), math.sqrt(6 / (dimensions[0] + dimensions[1]))]},\n",
    "    {'b':[0, 0],'w':[-math.sqrt(6 / (dimensions[1] + dimensions[2])), math.sqrt(6 / (dimensions[1] + dimensions[2]))]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters_b(layer):\n",
    "    dist=distribution[layer]['b']\n",
    "    return np.random.rand(dimensions[layer])*(dist[1]-dist[0])+dist[0]\n",
    "def init_parameters_w(layer):\n",
    "    dist=distribution[layer]['w']\n",
    "    return np.random.rand(dimensions[layer-1],dimensions[layer])*(dist[1]-dist[0])+dist[0]\n",
    "def init_parameters():\n",
    "    parameter = []\n",
    "    for i in range(len(distribution)):\n",
    "        layer_parameter = {}\n",
    "        for j in distribution[i].keys():\n",
    "            if j == 'b':\n",
    "                layer_parameter['b'] = init_parameters_b(i)\n",
    "                continue\n",
    "            if j == 'w':\n",
    "                layer_parameter['w'] = init_parameters_w(i)\n",
    "                continue\n",
    "        parameter.append(layer_parameter)\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img,parameters):\n",
    "    l_in = img\n",
    "    l_out = activation[0](l_in)\n",
    "    for layer in range(1, len(dimensions)):\n",
    "        l_in = np.dot(l_out,parameters[layer]['w']) + parameters[layer]['b']\n",
    "        l_out = activation[layer](l_in)\n",
    "    return l_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('./MNIST')\n",
    "train_img_path = dataset_path / 'train-images.idx3-ubyte'\n",
    "train_lab_path = dataset_path / 'train-labels.idx1-ubyte'\n",
    "test_img_path = dataset_path / 't10k-images.idx3-ubyte'\n",
    "test_lab_path = dataset_path / 't10k-labels.idx1-ubyte'\n",
    "train_num=50000\n",
    "valid_num=10000\n",
    "test_num=10000\n",
    "\n",
    "with open(train_img_path,'rb') as f:\n",
    "    struct.unpack('>4i',f.read(16))\n",
    "    tmp_img=np.fromfile(f,dtype=np.uint8).reshape(-1,28*28)/255\n",
    "    train_img=tmp_img[:train_num]\n",
    "    valid_img=tmp_img[train_num:]\n",
    "    \n",
    "with open(test_img_path,'rb') as f:\n",
    "    struct.unpack('>4i',f.read(16))\n",
    "    test_img=np.fromfile(f,dtype=np.uint8).reshape(-1,28*28)/255\n",
    "\n",
    "with open(train_lab_path,'rb') as f:\n",
    "    struct.unpack('>2i',f.read(8))\n",
    "    tmp_lab=np.fromfile(f,dtype=np.uint8)\n",
    "    train_lab=tmp_lab[:train_num]\n",
    "    valid_lab=tmp_lab[train_num:]\n",
    "    \n",
    "with open(test_lab_path,'rb') as f:\n",
    "    struct.unpack('>2i',f.read(8))\n",
    "    test_lab=np.fromfile(f,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train(index):\n",
    "    plt.imshow(train_img[index].reshape(28,28),cmap='gray')\n",
    "    print('label : {}'.format(train_lab[index]))\n",
    "def show_valid(index):\n",
    "    plt.imshow(valid_img[index].reshape(28,28),cmap='gray')\n",
    "    print('label : {}'.format(valid_lab[index]))\n",
    "def show_test(index):\n",
    "    plt.imshow(test_img[index].reshape(28,28),cmap='gray')\n",
    "    print('label : {}'.format(test_lab[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.44642113e-05  1.31054825e-05  1.16053365e-05  1.97533922e-05]\n",
      "[ 1.99645700e-05 -4.80940363e-05  1.47914392e-05  1.33380272e-05]\n",
      "[ 1.19877075e-05  1.48912282e-05 -4.73123230e-05  2.04333872e-05]\n",
      "[ 1.58115703e-05  1.17123885e-05  1.57793249e-05 -4.33032837e-05]\n"
     ]
    }
   ],
   "source": [
    "h=0.001\n",
    "func=softmax\n",
    "input_len=4\n",
    "for i in range(input_len):\n",
    "    test_input=np.random.rand(input_len)\n",
    "    derivative=differential[func](test_input)\n",
    "    value1=func(test_input)\n",
    "    test_input[i]+=h\n",
    "    value2=func(test_input)\n",
    "#     print((value2-value1)/h)\n",
    "#     print(derivative[i])\n",
    "    print(derivative[i]-(value2-value1)/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.799985560259955e-05\n",
      "1.0110819491426781e-05\n",
      "3.83452982636312e-05\n",
      "2.9673263405416428e-05\n"
     ]
    }
   ],
   "source": [
    "h=0.0001\n",
    "func=tanh\n",
    "input_len=4\n",
    "for i in range(input_len):\n",
    "    test_input=np.random.rand(input_len)\n",
    "    derivative=differential[func](test_input)\n",
    "    value1=func(test_input)\n",
    "    test_input[i]+=h\n",
    "    value2=func(test_input)\n",
    "#     print((value2-value1)/h)\n",
    "#     print(derivative[i])\n",
    "    print(derivative[i]-((value2-value1)/h)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "onehot = np.identity(dimensions[-1])\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqr_loss(img, lab, parameters):\n",
    "    y_pred = predict(img, parameters)\n",
    "    y = onehot[lab]\n",
    "    diff = y - y_pred\n",
    "    return np.dot(diff, diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{d}{dx}f_1(f_2(f_3(.....f_n())))=$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算梯度\n",
    "def grad_parameters(img, lab,parameters):\n",
    "    # 第一层\n",
    "    l_in_list = [img]\n",
    "    l_out_list = [activation[0](l_in_list[0])]\n",
    "    # 把网络上所有的输入输出存下俩\n",
    "    for layer in range(1, len(dimensions)):\n",
    "        l_in = np.dot(l_out_list[layer - 1], parameters[layer]['w']) + parameters[layer]['b']\n",
    "        l_out = activation[layer](l_in)\n",
    "        l_in_list.append(l_in)\n",
    "        l_out_list.append(l_out)\n",
    "    \n",
    "    d_layer = -2 * (onehot[lab] - l_out_list[-1])\n",
    "    \n",
    "    grad_result = [None] * len(dimensions)\n",
    "    for layer in range(len(dimensions)-1, 0, -1):\n",
    "        if d_type[activation[layer]] == 'times':\n",
    "            d_layer = differential[activation[layer]](l_in_list[layer]) * d_layer\n",
    "        if d_type[activation[layer]] == 'dot':\n",
    "            d_layer = np.dot(differential[activation[layer]](l_in_list[layer]), d_layer)\n",
    "        grad_result[layer] = {}\n",
    "        grad_result[layer]['b'] = d_layer\n",
    "        grad_result[layer]['w'] = np.outer(l_out_list[layer - 1], d_layer)\n",
    "        d_layer=np.dot(parameters[layer]['w'], d_layer)\n",
    "    \n",
    "    return grad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=init_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7686415523680017e-07"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=0.00001\n",
    "layer=2\n",
    "pname='b'\n",
    "grad_list=[]\n",
    "for i in range(len(parameters[layer][pname])):\n",
    "    img_i=np.random.randint(train_num)\n",
    "    test_parameters=init_parameters()\n",
    "    derivative=grad_parameters(train_img[img_i],train_lab[img_i],test_parameters)[layer][pname]\n",
    "    value1=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "    test_parameters[layer][pname][i]+=h\n",
    "    value2=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "    grad_list.append(derivative[i]-(value2-value1)/h)\n",
    "np.abs(grad_list).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.661868855266536e-07"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=0.00001\n",
    "layer=1\n",
    "pname='b'\n",
    "grad_list=[]\n",
    "for i in range(len(parameters[layer][pname])):\n",
    "    img_i=np.random.randint(train_num)\n",
    "    test_parameters=init_parameters()\n",
    "    derivative=grad_parameters(train_img[img_i],train_lab[img_i],test_parameters)[layer][pname]\n",
    "    value1=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "    test_parameters[layer][pname][i]+=h\n",
    "    value2=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "    grad_list.append(derivative[i]-(value2-value1)/h)\n",
    "np.abs(grad_list).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.260777898246193e-05"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=0.001\n",
    "layer=2\n",
    "pname='w'\n",
    "grad_list=[]\n",
    "for i in range(len(parameters[layer][pname])):\n",
    "    for j in range(len(parameters[layer][pname][0])):\n",
    "        img_i=np.random.randint(train_num)\n",
    "        test_parameters=init_parameters()\n",
    "        derivative=grad_parameters(train_img[img_i],train_lab[img_i],test_parameters)[layer][pname]\n",
    "        value1=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "        test_parameters[layer][pname][i][j]+=h\n",
    "        value2=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "        grad_list.append(derivative[i][j]-(value2-value1)/h)\n",
    "np.abs(grad_list).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h=0.00001\n",
    "# layer=1\n",
    "# pname='w'\n",
    "# grad_list=[]\n",
    "# for i in range(len(parameters[layer][pname])):\n",
    "#     for j in range(len(parameters[layer][pname][0])):\n",
    "#         img_i=np.random.randint(train_num)\n",
    "#         test_parameters=init_parameters()\n",
    "#         derivative=grad_parameters(train_img[img_i],train_lab[img_i],test_parameters)[layer][pname]\n",
    "#         value1=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "#         test_parameters[layer][pname][i][j]+=h\n",
    "#         value2=sqr_loss(train_img[img_i],train_lab[img_i],test_parameters)\n",
    "#         grad_list.append(derivative[i][j]-(value2-value1)/h)\n",
    "# np.abs(grad_list).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loss(parameters):\n",
    "    loss_accu=0\n",
    "    for img_i in range(valid_num):\n",
    "        loss_accu+=sqr_loss(valid_img[img_i],valid_lab[img_i],parameters)\n",
    "    return loss_accu/(valid_num/10000)\n",
    "def valid_accuracy(parameters):\n",
    "    correct=[predict(valid_img[img_i],parameters).argmax()==valid_lab[img_i] for img_i in range(valid_num)]\n",
    "    return correct.count(True)/len(correct)\n",
    "def train_loss(parameters):\n",
    "    loss_accu=0\n",
    "    for img_i in range(train_num):\n",
    "        loss_accu+=sqr_loss(train_img[img_i],train_lab[img_i],parameters)\n",
    "    return loss_accu/(train_num/10000)\n",
    "def train_accuracy(parameters):\n",
    "    correct=[predict(train_img[img_i],parameters).argmax()==train_lab[img_i] for img_i in range(train_num)]\n",
    "    return correct.count(True)/len(correct)\n",
    "def test_accuracy(parameters):\n",
    "    correct=[predict(test_img[img_i],parameters).argmax()==test_lab[img_i] for img_i in range(test_num)]\n",
    "    return correct.count(True)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_add(grad1, grad2):\n",
    "    for layer in range(1, len(grad1)):\n",
    "        for pname in grad1[layer].keys():\n",
    "            grad1[layer][pname] += grad2[layer][pname]\n",
    "    return grad1\n",
    "def grad_divide(grad, denominator):\n",
    "    for layer in range(1, len(grad)):\n",
    "        for pname in grad[layer].keys():\n",
    "            grad[layer][pname] /= denominator\n",
    "    return grad\n",
    "\n",
    "def combine_parameters(parameters,grad,learn_rate):\n",
    "    parameter_tmp=copy.deepcopy(parameters)\n",
    "    for layer in range(1,len(parameter_tmp)):\n",
    "        for pname in parameter_tmp[layer].keys():\n",
    "            parameter_tmp[layer][pname]-=learn_rate*grad[layer][pname]\n",
    "    return parameter_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "def train_batch(current_batch,parameters):\n",
    "    grad_accu=grad_parameters(train_img[current_batch*batch_size+0],train_lab[current_batch*batch_size+0],parameters)\n",
    "    for img_i in range(1,batch_size):\n",
    "        grad_tmp=grad_parameters(train_img[current_batch*batch_size+img_i],train_lab[current_batch*batch_size+img_i],parameters)\n",
    "        grad_add(grad_accu, grad_tmp)\n",
    "    grad_divide(grad_accu, batch_size)\n",
    "    return grad_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = init_parameters()\n",
    "current_epoch = 0\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "train_accu_list = []\n",
    "valid_accu_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的正确率: 0.09574\n",
      "验证集的正确率: 0.09210\n",
      "测试集的正确率: 0.08690\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集的正确率: {:.5f}\".format(train_accuracy(parameters))) # 训练之后的正确率\n",
    "print(\"验证集的正确率: {:.5f}\".format(valid_accuracy(parameters))) # 训练之后的正确率\n",
    "print(\"测试集的正确率: {:.5f}\".format(test_accuracy(parameters)))  # 训练之后的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[████████████████████████████████████████████████████████████] 100.0% \u001b[32mComplete\u001b[0m"
     ]
    }
   ],
   "source": [
    "learn_rate = 1 \n",
    "epoch_num = 1\n",
    "total_steps = train_num // batch_size * epoch_num\n",
    "progress_bar = ProgressBar(total_steps)\n",
    "for epoch in range(epoch_num):\n",
    "    for i in range(train_num//batch_size):\n",
    "        progress_bar.update(epoch * (train_num // batch_size) + i + 1)\n",
    "        grad_tmp = train_batch(i, parameters)\n",
    "        parameters = combine_parameters(parameters, grad_tmp, learn_rate)\n",
    "    current_epoch += 1\n",
    "    train_loss_list.append(train_loss(parameters))\n",
    "    train_accu_list.append(train_accuracy(parameters))\n",
    "    valid_loss_list.append(valid_loss(parameters))\n",
    "    valid_accu_list.append(valid_accuracy(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的正确率: 0.93166\n",
      "验证集的正确率: 0.93650\n",
      "测试集的正确率: 0.93280\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集的正确率: {:.5f}\".format(train_accuracy(parameters))) # 训练之后的正确率\n",
    "print(\"验证集的正确率: {:.5f}\".format(valid_accuracy(parameters))) # 训练之后的正确率\n",
    "print(\"测试集的正确率: {:.5f}\".format(test_accuracy(parameters)))  # 训练之后的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower = -5\n",
    "plt.plot(valid_loss_list[lower:], color='black', label='validation loss')\n",
    "plt.plot(train_loss_list[lower:], color='red', label='train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_accu_list[lower:], color='black', label='validation accuracy')\n",
    "plt.plot(train_accu_list[lower:], color='red', label='train accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                            ] 0.0% \u001b[31mProgress\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     learn_rate \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m lr_pow\n\u001b[0;32m     11\u001b[0m     parameters_tmp \u001b[39m=\u001b[39m combine_parameters(parameters, grad_lr, learn_rate)\n\u001b[1;32m---> 12\u001b[0m     train_loss_tmp \u001b[39m=\u001b[39m train_loss(parameters_tmp)\n\u001b[0;32m     13\u001b[0m     lr_list\u001b[39m.\u001b[39mappend([lr_pow, train_loss_tmp])\n\u001b[0;32m     14\u001b[0m progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39mint\u001b[39m((upper \u001b[39m-\u001b[39m lower) \u001b[39m/\u001b[39m step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[49], line 12\u001b[0m, in \u001b[0;36mtrain_loss\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m     10\u001b[0m loss_accu\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m img_i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(train_num):\n\u001b[1;32m---> 12\u001b[0m     loss_accu\u001b[39m+\u001b[39m\u001b[39m=\u001b[39msqr_loss(train_img[img_i],train_lab[img_i],parameters)\n\u001b[0;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m loss_accu\u001b[39m/\u001b[39m(train_num\u001b[39m/\u001b[39m\u001b[39m10000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m, in \u001b[0;36msqr_loss\u001b[1;34m(img, lab, parameters)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msqr_loss\u001b[39m(img, lab, parameters):\n\u001b[1;32m----> 2\u001b[0m     y_pred \u001b[39m=\u001b[39m predict(img, parameters)\n\u001b[0;32m      3\u001b[0m     y \u001b[39m=\u001b[39m onehot[lab]\n\u001b[0;32m      4\u001b[0m     diff \u001b[39m=\u001b[39m y \u001b[39m-\u001b[39m y_pred\n",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(img, parameters)\u001b[0m\n\u001b[0;32m      3\u001b[0m l_out \u001b[39m=\u001b[39m activation[\u001b[39m0\u001b[39m](l_in)\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(dimensions)):\n\u001b[1;32m----> 5\u001b[0m     l_in \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(l_out,parameters[layer][\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m+\u001b[39m parameters[layer][\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     l_out \u001b[39m=\u001b[39m activation[layer](l_in)\n\u001b[0;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m l_out\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rand_batch = np.random.randint(train_num // batch_size) # 随机取一个训练集\n",
    "grad_lr = train_batch(rand_batch, parameters) # 目前的梯度\n",
    "lr_list = []\n",
    "lower = -0.5\n",
    "upper = 0.5\n",
    "step = 0.1\n",
    "progress_bar = ProgressBar(int((upper - lower) / step + 1))\n",
    "for i, lr_pow in enumerate(np.linspace(lower, upper, num = int((upper - lower) / step + 1))):\n",
    "    progress_bar.update(i)\n",
    "    learn_rate = 10 ** lr_pow\n",
    "    parameters_tmp = combine_parameters(parameters, grad_lr, learn_rate)\n",
    "    train_loss_tmp = train_loss(parameters_tmp)\n",
    "    lr_list.append([lr_pow, train_loss_tmp])\n",
    "progress_bar.update(int((upper - lower) / step + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m upper\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(lr_list) \u001b[39m# 寻找学习率最合适的点(谷底也就是训练损失最低的点)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39;49marray(lr_list)[:upper, \u001b[39m0\u001b[39;49m], np\u001b[39m.\u001b[39marray(lr_list)[:upper,\u001b[39m1\u001b[39m], color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "upper=len(lr_list) # 寻找学习率最合适的点(谷底也就是训练损失最低的点)\n",
    "plt.plot(np.array(lr_list)[:upper, 0], np.array(lr_list)[:upper,1], color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(784, 100)\n",
      "(10,)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(parameters[1]['b'].shape)\n",
    "print(parameters[1]['w'].shape)\n",
    "print(parameters[2]['b'].shape)\n",
    "print(parameters[2]['w'].shape)\n",
    "np.savetxt('p_1_b.txt', parameters[1]['b'], fmt = \"%.5f\")\n",
    "np.savetxt('p_1_w.txt', parameters[1]['w'], fmt = \"%.5f\")\n",
    "np.savetxt('p_2_b.txt', parameters[2]['b'], fmt = \"%.5f\")\n",
    "np.savetxt('p_2_w.txt', parameters[2]['w'], fmt = \"%.5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_save = init_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = np.loadtxt('./p_1_b.txt', dtype=np.float32).reshape(100,)\n",
    "w1 = np.loadtxt('./p_1_w.txt', dtype=np.float32).reshape(784, 100)\n",
    "b2 = np.loadtxt('./p_2_b.txt', dtype=np.float32).reshape(10,)\n",
    "w2 = np.loadtxt('./p_2_w.txt', dtype=np.float32).reshape(100, 10)\n",
    "\n",
    "parameters_save = {\n",
    "    1: {'b': b1, 'w': w1},\n",
    "    2: {'b': b2, 'w': w2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9328\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy(parameters_save))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
