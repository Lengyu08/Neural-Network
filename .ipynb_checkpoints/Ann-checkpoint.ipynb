{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "import struct\n",
    "\n",
    "import numpy as np                  # 矩阵\n",
    "import matplotlib.pyplot as plt     # 绘图\n",
    "\n",
    "from numba import njit              # 加速 cpu\n",
    "from numba import cuda              # 加速 gpu(cuda)\n",
    "from pathlib import Path            # 处理路径\n",
    "\n",
    "from Activation import Activation\n",
    "from ProgressBar import ProgressBar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bypass(x):\n",
    "    return x\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def softmax(x):\n",
    "    exp=np.exp(x - x.max())\n",
    "    return exp / exp.sum()\n",
    "\n",
    "def d_softmax(data):\n",
    "    sm = softmax(data)\n",
    "    return np.diag(sm) - np.outer(sm,sm)\n",
    "\n",
    "def d_tanh(data):\n",
    "    return 1 / ((np.cosh(data)) ** 2)\n",
    "\n",
    "def d_bypass(x):\n",
    "    return 1\n",
    "\n",
    "differential = {softmax:d_softmax, tanh:d_tanh, bypass:d_bypass}\n",
    "d_type = {bypass:'times', softmax:'dot', tanh:'times'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions=[28*28, 100, 10]\n",
    "activation=[bypass,tanh,softmax]\n",
    "distribution=[\n",
    "    {}, # leave it empty!!\n",
    "    {'b':[0, 0],'w':[-math.sqrt(6 / (dimensions[0] + dimensions[1])), math.sqrt(6 / (dimensions[0] + dimensions[1]))]},\n",
    "    {'b':[0, 0],'w':[-math.sqrt(6 / (dimensions[1] + dimensions[2])), math.sqrt(6 / (dimensions[1] + dimensions[2]))]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters_b(layer):\n",
    "    dist=distribution[layer]['b']\n",
    "    return np.random.rand(dimensions[layer])*(dist[1]-dist[0])+dist[0]\n",
    "def init_parameters_w(layer):\n",
    "    dist=distribution[layer]['w']\n",
    "    return np.random.rand(dimensions[layer-1],dimensions[layer])*(dist[1]-dist[0])+dist[0]\n",
    "def init_parameters():\n",
    "    parameter=[]\n",
    "    for i in range(len(distribution)):\n",
    "        layer_parameter={}\n",
    "        for j in distribution[i].keys():\n",
    "            if j=='b':\n",
    "                layer_parameter['b']=init_parameters_b(i)\n",
    "                continue\n",
    "            if j=='w':\n",
    "                layer_parameter['w']=init_parameters_w(i)\n",
    "                continue\n",
    "        parameter.append(layer_parameter)\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def predict(img,parameters):\n",
    "    l_in = img\n",
    "    l_out = activation[0](l_in)\n",
    "    for layer in range(1, len(dimensions)):\n",
    "        l_in = np.dot(l_out,parameters[layer]['w']) + parameters[layer]['b']\n",
    "        l_out = activation[layer](l_in)\n",
    "    return l_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=Path('./MNIST')\n",
    "train_img_path=dataset_path/'train-images.idx3-ubyte'\n",
    "train_lab_path=dataset_path/'train-labels.idx1-ubyte'\n",
    "test_img_path=dataset_path/'t10k-images.idx3-ubyte'\n",
    "test_lab_path=dataset_path/'t10k-labels.idx1-ubyte'\n",
    "train_num=50000\n",
    "valid_num=10000\n",
    "test_num=10000\n",
    "\n",
    "with open(train_img_path,'rb') as f:\n",
    "    struct.unpack('>4i',f.read(16))\n",
    "    tmp_img=np.fromfile(f,dtype=np.uint8).reshape(-1,28*28)/255\n",
    "    train_img=tmp_img[:train_num]\n",
    "    valid_img=tmp_img[train_num:]\n",
    "    \n",
    "with open(test_img_path,'rb') as f:\n",
    "    struct.unpack('>4i',f.read(16))\n",
    "    test_img=np.fromfile(f,dtype=np.uint8).reshape(-1,28*28)/255\n",
    "\n",
    "with open(train_lab_path,'rb') as f:\n",
    "    struct.unpack('>2i',f.read(8))\n",
    "    tmp_lab=np.fromfile(f,dtype=np.uint8)\n",
    "    train_lab=tmp_lab[:train_num]\n",
    "    valid_lab=tmp_lab[train_num:]\n",
    "    \n",
    "with open(test_lab_path,'rb') as f:\n",
    "    struct.unpack('>2i',f.read(8))\n",
    "    test_lab=np.fromfile(f,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train(index):\n",
    "    plt.imshow(train_img[index].reshape(28,28),cmap='gray')\n",
    "    print('label : {}'.format(train_lab[index]))\n",
    "def show_valid(index):\n",
    "    plt.imshow(valid_img[index].reshape(28,28),cmap='gray')\n",
    "    print('label : {}'.format(valid_lab[index]))\n",
    "def show_test(index):\n",
    "    plt.imshow(test_img[index].reshape(28,28),cmap='gray')\n",
    "    print('label : {}'.format(test_lab[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.38398683e-08  1.43363794e-08  1.17142974e-08  1.78447027e-08]\n",
      "[ 1.15414990e-08 -4.61081562e-08  1.44046132e-08  2.04395997e-08]\n",
      "[ 1.12630559e-08  1.98613416e-08 -4.69250933e-08  1.58006958e-08]\n",
      "[ 1.97459042e-08  1.44457042e-08  1.38065307e-08 -4.81091614e-08]\n"
     ]
    }
   ],
   "source": [
    "h=0.001\n",
    "func=softmax\n",
    "input_len=4\n",
    "for i in range(input_len):\n",
    "    test_input=np.random.rand(input_len)\n",
    "    derivative=differential[func](test_input)\n",
    "    value1=func(test_input)\n",
    "    test_input[i]+=h\n",
    "    value2=func(test_input)\n",
    "#     print((value2-value1)/h)\n",
    "#     print(derivative[i])\n",
    "    print(derivative[i]-(value2-value1)/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.646287178737939e-05\n",
      "3.353441710435279e-05\n",
      "3.555732824811475e-05\n",
      "3.6677830799525246e-05\n"
     ]
    }
   ],
   "source": [
    "h=0.0001\n",
    "func=tanh\n",
    "input_len=4\n",
    "for i in range(input_len):\n",
    "    test_input=np.random.rand(input_len)\n",
    "    derivative=differential[func](test_input)\n",
    "    value1=func(test_input)\n",
    "    test_input[i]+=h\n",
    "    value2=func(test_input)\n",
    "#     print((value2-value1)/h)\n",
    "#     print(derivative[i])\n",
    "    print(derivative[i]-((value2-value1)/h)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "onehot = np.identity(dimensions[-1])\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqr_loss(img, lab, parameters):\n",
    "    y_pred = predict(img, parameters)\n",
    "    y = onehot[lab]\n",
    "    diff = y - y_pred\n",
    "    return np.dot(diff, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算梯度\n",
    "def grad_parameters(img, lab,parameters):\n",
    "    l_in_list = [img]\n",
    "    l_out_list = [activation[0](l_in_list[0])]\n",
    "    for layer in range(1, len(dimensions)):\n",
    "        l_in = np.dot(l_out_list[layer-1],parameters[layer]['w'])+parameters[layer]['b']\n",
    "        l_out=activation[layer](l_in)\n",
    "        l_in_list.append(l_in)\n",
    "        l_out_list.append(l_out)\n",
    "    \n",
    "    d_layer = -2 * (onehot[lab] - l_out_list[-1])\n",
    "    \n",
    "    grad_result = [None] * len(dimensions)\n",
    "    for layer in range(len(dimensions)-1, 0, -1):\n",
    "        if d_type[activation[layer]] == 'times':\n",
    "            d_layer = differential[activation[layer]](l_in_list[layer]) * d_layer\n",
    "        if d_type[activation[layer]] == 'dot':\n",
    "            d_layer=np.dot(differential[activation[layer]](l_in_list[layer]), d_layer)\n",
    "        grad_result[layer] = {}\n",
    "        grad_result[layer]['b'] = d_layer\n",
    "        grad_result[layer]['w'] = np.outer(l_out_list[layer-1], d_layer)\n",
    "        d_layer=np.dot(parameters[layer]['w'], d_layer)\n",
    "    \n",
    "    return grad_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
